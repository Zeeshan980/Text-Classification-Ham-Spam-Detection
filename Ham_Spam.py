# -*- coding: utf-8 -*-
"""Spam_Classification_Assessment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RDOn7m4bNawd7Q3sxXeh_Em21xVEflDE

# Brightloom NLP assessment

## 1. Data Preprocessing and Exploratory Data Analysis (EDA):
"""

import pandas as pd
import numpy as np
import re
import nltk
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
  f1_score, roc_auc_score, roc_curve, auc, confusion_matrix)
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud, STOPWORDS
import tensorflow_hub as hub
import tensorflow_text as text
from sklearn.svm import SVC
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dense
from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

"""Downloading the 'punkt' tokenizer and the 'stopwords' corpus along with the required libraries

"""

nltk.download('punkt')
nltk.download('stopwords')

"""Loading the data"""

raw_data = pd.read_csv('spam.csv',encoding="latin-1")
data = raw_data.copy()
data.head()

"""Checking for null values"""

nan_counts = data.isnull().sum()
print(nan_counts)

"""As it can be observed above, the dataframe did not contain any NaN values.

Create Common function to Clean or process Text Data
Lower casing to avoids duplicates
* Tokenization sentences
* Remove Specials characters
* Remove Stopwords
* Remove punctuation
"""

def preprocess_text(text):
    text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    text = text.lower()
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words("english"))
    tokens = [token for token in tokens if token not in stop_words]
    return " ".join(tokens)

data["text"] = data["text"].apply(preprocess_text)

"""Visialized the count of words for Spam and Ham Messages:"""

def show_wordcloud(data, pos_label, text_column='text', colormap='viridis', width=800, height=600):
    filtered_data = data[data['class'] == pos_label]
    text = ' '.join(filtered_data[text_column].astype(str).tolist())
    fig_wordcloud = WordCloud(background_color='rgba(255, 255, 255, 0)',
                              colormap=colormap, width=width, height=height).generate(text)
    plt.figure(figsize=(12, 8))
    plt.imshow(fig_wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"Word Cloud for {pos_label.capitalize()} Messages", fontsize=24, fontweight='bold', pad=20)
    plt.show()

show_wordcloud(data, pos_label="spam")

show_wordcloud(data, pos_label="ham")

print('Label distribution (%):', round(data['class'].value_counts(normalize=True),3)*100)
plt.figure(figsize=(8,2))
ax=sns.countplot(data=data, y='class')
for container in ax.containers:
    ax.bar_label(container)
plt.tight_layout()

"""Only about 15% of the data provided are spam rest are all legit messages"""

data['text_length'] = data['text'].apply(len)
plt.figure(figsize=(10, 6))
sns.histplot(data, x='text_length', hue='class', bins=30, kde=True)
plt.title('Text Length Analysis')
plt.show()

"""Majority of the legit texts have shorter lengths (<100 words). On the other hand spam messages are relatively longer"""

data['unique_word_length'] = data['text'].apply(lambda x: len(set(word_tokenize(x.lower()))))
plt.figure(figsize=(10, 6))
sns.boxplot(x='class', y='unique_word_length', data=data)
plt.title('Length of Unique Words Analysis')
plt.show()

"""On the contrary to the previous finding, legit messages tend to have more unique words than the spam messages"""

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(data["text"])
y = data["class"]

"""To enhance the quality and effectiveness of natural language processing (NLP) models, text preprocessing and feature extraction were performed. The input text undergoes several preprocessing steps, including conversion to lowercase for uniformity, removal of non-alphabetic characters using a regular expression, tokenization using the word_tokenize function, and elimination of common stop words via NLTK's English stop words. Following this preprocessing, the text is fed into a CountVectorizer from the scikit-learn library. The CountVectorizer facilitates the conversion of the preprocessed text into a matrix of token counts, wherein each row corresponds to a document, and each column represents the count of a specific token. The results were saved in a matrix 'x' which can be the used as a feature set for our ML models.

### 2. Model Development - Basic:

#### Multinomial NB

Multinomial Naive Bayes is a probabilistic classification algorithm commonly used for text and document classification. The dataset is split into training and testing sets, and the classifier is trained on the training data.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

classifier = MultinomialNB()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred,pos_label="spam")
recall = recall_score(y_test, y_pred, pos_label="spam")
f1 = f1_score(y_test, y_pred, pos_label="spam")

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["non-spam", "spam"], yticklabels=["non-spam", "spam"])
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""The Multinomial Naive Bayes model achieved high accuracy and demonstrated strong precision and recall, indicating effective positive class identification.

#### SVM Classifier

The Support Vector Machine (SVM) classification technique creates a robust decision boundary between spam and non-spam messages. By maximizing the margin between classes, SVM effectively distinguishes intricate patterns, making it adept at handling high-dimensional feature spaces inherent in text data.
"""

classifier = SVC(kernel='linear')
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label="spam")
recall = recall_score(y_test, y_pred, pos_label="spam")
f1 = f1_score(y_test, y_pred, pos_label="spam")

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

conf_matrix_svm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_svm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non-Spam", "Spam"], yticklabels=["Non-Spam", "Spam"])
plt.title("Confusion Matrix - SVM")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

y_test1 = [int(x == 'spam') for x in y_test]
y_pred1 = [int(x == 'spam') for x in y_pred]
roc_auc_svm = roc_auc_score(y_test1, y_pred1)

fpr_svm, tpr_svm, _ = roc_curve(y_test1, y_pred1)

plt.figure(figsize=(8, 6))
plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_svm))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - SVM')
plt.legend(loc='lower right')
plt.show()

"""The SVM model showcases very good precision, accurately identifying spam instances, albeit with a slightly lower recall. Overall, the balanced F1-score of 89.9% emphasizes the classifier's effectiveness in spam detection.

#### XGBoost Classifier

XGBoost sequentially builds an ensemble of weak learners, to iteratively improve predictive performance. XGBoost's ensemble approach, combining weak learners, enhances both the precision and recall values, making it well-suited for effectively discerning spam messages while maintaining a high overall accuracy
"""

data = pd.read_csv('spam.csv',encoding="latin-1")
data['class'] = data['class'].map({"ham": 0, "spam": 1})

X_train, X_test, y_train, y_test = train_test_split(
    data['text'], data['class'], test_size=0.2, random_state=42)

vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

model = XGBClassifier()

param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 200],
}

grid_search = GridSearchCV(model, param_grid, cv=3, scoring='precision')
grid_search.fit(X_train_vectorized, y_train)

print("Best Hyperparameters:", grid_search.best_params_)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_vectorized)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

"""For the XGBoost model, the identified best hyperparameters include a learning rate of 0.2, a maximum tree depth of 4, and 200 estimators. In terms of spam classification, the model exhibits strong performance. XGBoost maintains high accuracy while effectively capturing a substantial portion of spam instances (recall) and minimizing false positives (precision).

#### RNN Model

A Recurrent Neural Network (RNN) is a type of neural network designed for sequence data, capable of capturing temporal dependencies by maintaining hidden states.

Long Short-Term Memory (LSTM) is a specialized type of RNN designed to overcome the vanishing gradient problem.

LSTMs excel at handling the intricate patterns present in language, enabling them to discern nuanced features in emails or messages, making them a powerful choice for spam detection tasks.
"""

data = raw_data.copy()
X = data["text"]
y = data["class"]
y = y.map({"spam": 1, "ham": 0})

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(X)
sequences = tokenizer.texts_to_sequences(X)

max_length = 100
data_padded = pad_sequences(sequences, maxlen=max_length)

X_train, X_test, y_train, y_test = train_test_split(data_padded, y, test_size=0.2)

vocab_size = len(tokenizer.word_index) + 1
embedding_dim = 100
model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=max_length),
    LSTM(units=64, dropout=0.2),
    Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['Predicted Non-Spam', 'Predicted Spam'], rotation=0)
plt.yticks([0, 1], ['Actual Non-Spam', 'Actual Spam'])
for i in range(2):
    for j in range(2):
        plt.text(j, i, str(conf_matrix[i, j]), ha='center', va='center', color='black')

roc_auc = roc_auc_score(y_test, y_pred)

fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc_curve = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_curve))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""LSTM's high accuracy reflects the model's overall effectiveness, while the impressive precision and recall values emphasize its ability to minimize false positives and capture a substantial portion of actual spam instances.

#### BERT

BERT excels in spam classification due to its contextual understanding of language. Spam messages often contain subtle and context-dependent cues that traditional models may miss. BERT's ability to consider the entire context of a sentence enables it to grasp the semantics of messages, making it highly effective in discerning between legitimate and spam content.
"""

df = data.copy()
df['spam']=df['class'].apply(lambda x: 1 if x=='spam' else 0)
df.head()

X_train, X_test, y_train, y_test = train_test_split(df['text'],df['spam'], stratify=df['spam'])
X_train.head(4)

bert_preprocess = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
bert_encoder = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")
# Bert layers
text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
preprocessed_text = bert_preprocess(text_input)
outputs = bert_encoder(preprocessed_text)
# Neural network layers
l = tf.keras.layers.Dropout(0.1, name="dropout")(outputs['pooled_output'])
l = tf.keras.layers.Dense(1, activation='sigmoid', name="output")(l)
# Use inputs and outputs to construct a final model
model = tf.keras.Model(inputs=[text_input], outputs = [l])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['precision'])
model.fit(X_train, y_train, epochs=2, batch_size = 32)

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

y_predicted = model.predict(X_test)
y_predicted = y_predicted.flatten()
print(y_predicted)

accuracy = accuracy_score(y_test, y_predicted > 0.5)
precision = precision_score(y_test, y_predicted > 0.5)
recall = recall_score(y_test, y_predicted > 0.5)
f1 = f1_score(y_test, y_predicted > 0.5)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

bert_preprocess = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
bert_encoder = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")
# Bert layers
text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
preprocessed_text = bert_preprocess(text_input)
outputs = bert_encoder(preprocessed_text)


l = tf.keras.layers.Dropout(0.2, name="dropout1")(outputs['pooled_output'])
l = tf.keras.layers.Dense(128, activation='relu')(l)
l = tf.keras.layers.Dropout(0.2)(l)
l = tf.keras.layers.Dense(1, activation='sigmoid', name="output")(l)

model = tf.keras.Model(inputs=[text_input], outputs=[l])
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['precision'])

model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)

y_predicted = model.predict(X_test)
y_predicted = y_predicted.flatten()
print(y_predicted)

accuracy = accuracy_score(y_test, y_predicted > 0.5)
precision = precision_score(y_test, y_predicted > 0.5)
recall = recall_score(y_test, y_predicted > 0.5)
f1 = f1_score(y_test, y_predicted > 0.5)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

"""Bert has comparatively lower recall indicating challenges in capturing a significant portion of actual spam instances.Further optimization through hypoerperameter tuning could potentially enhance its effectiveness in spam detection tasks.

# Summary of Model Performances

In evaluating various models for spam classification, each exhibited distinctive strengths and trade-offs. The Multinomial Naive Bayes model demonstrated commendable performance with an accuracy of 97.4%, showcasing a balanced precision and recall. The Support Vector Machine (SVM) exhibited high precision at 98.4%, though with a slightly lower recall of 82.7%. XGBoost, with optimized hyperparameters, achieved a well-rounded performance with an accuracy of 97.5% and a balanced F1 score of 90.1%. The LSTM model showcased impressive results with an accuracy of 98.4%, emphasizing its proficiency in capturing precision and recall.

However, the BERT model, leveraging contextual understanding, presented competitive accuracy at 88.2%. Despite its relatively lower recall, BERT's capacity to comprehend intricate language nuances positions it as a strong contender for further exploration.

# Model To Choose

Precision is like having a trustworthy spam filter that doesn't wrongly label important emails as spam. If we prioritize precision in our model choice, such as with the Support Vector Machine (SVM) boasting 96.8%, we're ensuring that when the model says something is spam, it's highly likely to be accurate. This is essential for creating a reliable spam detection system that doesn't annoy users with false alarms for legitimate messages.
"""